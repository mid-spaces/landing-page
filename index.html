<!DOCTYPE html>
<html lang="en">
<head>
    <!-- Meta Tags -->
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MID-Space: Aligning Diverse Communities’ Needs to Inclusive Public Spaces</title>
    <meta name="description" content="MID-Space: A dataset aligning diverse community needs to inclusive public spaces using AI tools.">
    <meta name="keywords" content="MID-Space, Inclusive Public Spaces, AI, Dataset, NeurIPS 2024, Urban Design">
    <meta name="author" content="Your Name or Organization">

    <!-- Google Fonts -->
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap" rel="stylesheet">

    <!-- Font Awesome for Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css" integrity="sha512-Fo3rlrZj/k7ujTnHq6zQ5/Jt5Vv8gUPK/PgKjG1hgZHR1KJ+vWBbZ27ZKAXSf4VhUYxvMqenGEXBw2OxW4RR2w==" crossorigin="anonymous" referrerpolicy="no-referrer" />
    
    <!-- Favicon -->
    <link rel="icon" href="assets/images/favicon.ico" type="image/x-icon">

    <!-- AOS (Animate On Scroll) -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/aos/2.3.4/aos.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/aos/2.3.4/aos.js"></script>

    <!-- Custom CSS -->
    <link rel="stylesheet" href="assets/css/styles.css">

    <!-- Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=YOUR_TRACKING_ID"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
    
      gtag('config', 'YOUR_TRACKING_ID');
    </script>
</head>
<body>
    <!-- Header -->
    <header>
        <div class="container">
            <div class="logo-container">
                <a href="https://unesco-studio.umontreal.ca/" target="_blank">
                    <img src="assets/images/unesco.png" alt="UNESCO Logo" class="logo unesco-logo">
                </a>
                <a href="https://mila.quebec/en/ai4humanity/applied-projects/artificial-intelligence-alignment-for-inclusion-aiai" target="_blank">
                    <img src="assets/images/mila.png" alt="Mila Logo" class="logo mila-logo">
                </a>
            </div>
            <nav>
                <ul>
                    <li><a href="index.html" class="active">Home</a></li>
                    <li><a href="paper.html">Paper</a></li>
                </ul>
                <button class="toggle-button" aria-label="Toggle navigation">
                    <i class="fas fa-bars"></i>
                </button>
            </nav>
        </div>
    </header>

    <!-- Hero Section -->
    <section class="hero" data-aos="fade-up">
        <div class="container hero-content">
            <div class="hero-text">
                <h1>MID-Space</h1>
                <h2>Aligning Diverse Communities’ Needs to Inclusive Public Spaces</h2>
                <p>Democratizing the power of urban space visualization through inclusive AI tools.</p>
                <div class="hero-buttons">
                    <a href="dataset.html" class="btn primary-btn">Download Dataset</a>
                    <a href="paper.html" class="btn secondary-btn">Read Paper</a>
                    <a href="https://github.com/your-username/mid-space-code" target="_blank" class="btn code-btn">
                        <i class="fab fa-github"></i> View Code
                    </a>
                </div>
            </div>
            <div class="hero-image">
                <img src="assets/images/dpo.png" alt="MID-Space Visualization" loading="lazy">
            </div>
        </div>
    </section>

    <!-- Summary Section -->
    <section class="summary" data-aos="fade-up">
        <div class="container">
            <h2>Summary of the Paper</h2>
            <p>
                The MID-Space project aims to democratize urban space visualization by leveraging artificial intelligence to align AI-generated visualizations with the diverse needs and preferences of Montreal’s communities. By collaborating with various community organizations and utilizing the Stable Diffusion XL model, MID-Space bridges the gap between AI capabilities and inclusive urban design. The dataset comprises over 3,000 prompts and 42,000 annotations based on criteria such as accessibility, safety, diversity, inclusivity, invitingness, and comfort. This initiative empowers marginalized groups to have a more significant influence over the design and utilization of public spaces, ensuring that these environments are equitable, diverse, and welcoming to all.
            </p>
            <p>
                Our approach involves collecting a vast array of prompts that reflect real-world scenarios and preferences from diverse community members. Through meticulous annotation and data analysis, we ensure that the AI models trained on this dataset can generate visualizations that are not only aesthetically pleasing but also aligned with the fundamental values of inclusivity and diversity. The MID-Space dataset serves as a critical resource for urban planners, AI researchers, and community leaders to collaboratively design public spaces that cater to the nuanced needs of all community members.
            </p>
        </div>
    </section>

    <!-- Visualizations Carousel -->
    <section class="visualizations" data-aos="fade-up">
        <div class="container">
            <h2>Visualizations</h2>
            <div class="carousel">
                <div class="carousel-item">
                    <img src="assets/images/inside-mid.png" alt="Visualization 1" loading="lazy">
                    <div class="description">
                        <p><strong>Summary:</strong> The paper presents the MID-Space dataset, designed to align AI-generated images with the diverse preferences of various communities in urban public space design. By engaging community members through workshops, the researchers identified six key criteria—accessibility, safety, diversity, inclusivity, invitingness, and comfort—that define inclusive public spaces. The dataset includes textual prompts, AI-generated images, and annotations reflecting community preferences. Fine-tuning the Stable Diffusion XL (SDXL) model with this dataset enhances its ability to generate visualizations that meet the specific needs and values of different community groups, supporting urban designers in creating equitable public environments.</p>
                        <p><strong>Participatory Process:</strong> The MID-Space dataset was developed through collaboration with community organizations in Montreal. Community members participated in workshops to identify important attributes of inclusive public spaces. These sessions helped define six criteria for evaluation and gather prompts for image generation. A diverse group of annotators from various backgrounds then reviewed AI-generated images, providing preferences based on the identified criteria. This participatory approach ensured that the dataset reflects the authentic needs and priorities of different community groups.</p>
                        <p><strong>Dataset Content and Importance:</strong> The MID-Space dataset comprises textual prompts, corresponding AI-generated images, and annotations indicating preferences across six criteria: accessibility, safety, diversity, inclusivity, invitingness, and comfort. With over 3,000 unique public space concepts and more than 60,000 annotated image pairs, the dataset captures a wide range of community preferences. This diversity is crucial for pluralistic alignment, addressing valid but differing preferences among various groups. The dataset serves as a valuable resource for AI alignment researchers and urban designers aiming to create public spaces that accommodate multiple perspectives and promote equity.</p>
                        <p><strong>Results:</strong> The study involved fine-tuning the Stable Diffusion XL (SDXL) model using the MID-Space dataset through Direct Preference Optimization (DPO). Three versions of the model were developed:
                            <ul>
                                <li><strong>SDXL Original:</strong> The baseline model without fine-tuning, generating images based on its initial training data.</li>
                                <li><strong>SDXL-DPO for Inclusion Criterion:</strong> This version was fine-tuned specifically to align image generation with the inclusion criterion, ensuring that the resulting images reflect inclusive public space attributes.</li>
                                <li><strong>SDXL-DPO for All Six Criteria:</strong> A comprehensive model fine-tuned to consider all six criteria simultaneously, enabling the generation of images that meet multiple community-defined standards for inclusive public spaces.</li>
                            </ul>
                        </p>
                    </div>
                </div>
                <div class="carousel-item">
                    <img src="assets/images/part-mid.png" alt="Visualization 2" loading="lazy">
                    <div class="description">
                        <p><strong>Figure 2 Description:</strong> <em>Prompt:</em> A quiet, inclusive meditation garden in a busy urban area.</p>
                        <p>Figure 2 showcases images generated by three different models using the same seed, number of generation steps (50), and guidance scale (5).</p>
                        <p><strong>SDXL Original:</strong> Displays the baseline image generated without any fine-tuning.</p>
                        <p><strong>SDXL-DPO for Inclusion Criterion:</strong> Shows the image refined to emphasize inclusivity based on community preferences.</p>
                        <p><strong>SDXL-DPO for All Six Criteria:</strong> Presents the image aligned with all six criteria, reflecting a comprehensive approach to meeting diverse community needs.</p>
                        <p>Each version illustrates how fine-tuning the model with specific criteria influences the generated visualization of the meditation garden.</p>
                    </div>
                </div>
                <div class="carousel-item">
                    <img src="assets/images/creat-mid.png" alt="Visualization 3" loading="lazy">
                    <div class="description">
                        <p><strong>Visualization 3 Description:</strong> [Add your descriptive text here]</p>
                        <p>[Additional paragraph 2]</p>
                        <p>[Additional paragraph 3]</p>
                        <p>[Additional paragraph 4]</p>
                    </div>
                </div>
                <div class="carousel-item">
                    <img src="assets/images/results-mid.png" alt="Visualization 4" loading="lazy">
                    <div class="description">
                        <p><strong>Visualization 4 Description:</strong> [Add your descriptive text here]</p>
                        <p>[Additional paragraph 2]</p>
                        <p>[Additional paragraph 3]</p>
                        <p>[Additional paragraph 4]</p>
                    </div>
                </div>
            </div>
            <div class="carousel-controls">
                <button class="prev" aria-label="Previous Slide"><i class="fas fa-chevron-left"></i></button>
                <button class="next" aria-label="Next Slide"><i class="fas fa-chevron-right"></i></button>
            </div>
        </div>
    </section>

    <!-- Contact Information -->
    <section class="contact-info" data-aos="fade-up">
        <div class="container">
            <p><strong>For more information, contact:</strong> <a href="mailto:rashidmushkani@gmail.com">rashidmushkani@gmail.com</a></p>
        </div>
    </section>

    <!-- Footer -->
    <footer>
        <div class="container">
            <p>&copy; 2024 MID-Space. All rights reserved.</p>
            <p><a href="LICENSE">Template License (MIT)</a></p>
        </div>
    </footer>

    <!-- JavaScript for Carousel and Navigation Toggle -->
    <script src="assets/js/scripts.js"></script>
    <!-- Initialize AOS -->
    <script>
        AOS.init({
            duration: 800,
            once: true,
        });
    </script>
</body>
</html>
